# Scene Understanding Project

A comprehensive computer vision pipeline for advanced scene understanding, including 3D object detection, depth estimation, lane detection, and human pose estimation.

## ðŸŽ¯ Overview

This project combines multiple state-of-the-art computer vision models to provide a complete scene understanding solution:

- **3D Object Detection**: YOLOv11 with 3D bounding box estimation
- **Depth Estimation**: Depth Anything v2 for monocular depth prediction
- **Lane Detection**: Computer vision-based lane detection for autonomous driving
- **Human Pose Estimation**: VIBE (Video Inference for Human Body Pose and Shape Estimation)

## Project Structure

```
SceneUnderstanding/
â”œâ”€â”€ run.py                 # Main 3D object detection pipeline
â”œâ”€â”€ demo.py               # VIBE human pose estimation demo
â”œâ”€â”€ lane.py               # Lane detection implementation
â”œâ”€â”€ detection_model.py    # YOLOv11 object detection wrapper
â”œâ”€â”€ depth_model.py        # Depth Anything v2 wrapper
â”œâ”€â”€ bbox3d_utils.py       # 3D bounding box estimation utilities
â”œâ”€â”€ models.py             # SMPL models and neural network architectures
â”œâ”€â”€ img_utils.py          # Image processing and transformation utilities
â”œâ”€â”€ utils.py              # General utility functions
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ run.sh                # Setup and execution script
â””â”€â”€ vehicle_icons/        # Icons for vehicle visualization
    â”œâ”€â”€ bus_icon.png
    â”œâ”€â”€ car_icon.png
    â””â”€â”€ truck_icon.png
```

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (optional, but recommended)
- FFmpeg (for video processing)

### Setup
1. Clone the repository and navigate to the project directory
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Run the setup script:
   ```bash
   ./run.sh
   ```

### 3D Object Detection Pipeline
```bash
python run.py
```
This will:
1. Load the input video (`output_videos/Lane_Det.mp4`)
2. Perform object detection and tracking
3. Estimate depth for each detected object
4. Generate 3D bounding boxes
5. Create Bird's Eye View visualization
6. Save output video with 3D annotations